{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn 복습(F-9)\n",
    "### 머신러닝\n",
    "1. 데이터 분석\n",
    "2. 데이터 가공 : Feature Engineering(필요한 특징만 추출) & 데이터 전처리 & One-hot Encoding\n",
    "3. 데이터 분할 : 훈련 데이터와 테스트 데이터 분리\n",
    "4. 모델 추정 : 훈련(학습)\n",
    "5. 모델 평가\n",
    "\n",
    "### 데이터 표현\n",
    "Numpy의 ndarray, Pandas의 DataFrame, SciPy의 Sparse Matrix를 이용해서 데이터를 표현할 수 있다. 데이터는 **Feature Matrix**와 **Target Vector**로 나타낸다.\n",
    "* Feature Matrix\n",
    "    * 입력 데이터\n",
    "    * Feature : 데이터에서 수치 값, 이산 값, 불리언 값으로 표현되는 개별 관측치.\n",
    "* Target Vector\n",
    "    * 입력 데이터의 Label(정답)\n",
    "    * Target : Feature Matrix로부터 예측하고자 하는 것.\n",
    "\n",
    "### Data 표현 API\n",
    "* 데이터셋 제공 : `.datasets`\n",
    "* 데이터 전처리 : `.preprocessing`\n",
    "* 데이터 분리 : `.preprocessing`\n",
    "* 평가 : `.metrics`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Toy dataset 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "data = load_wine()\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape #데이터가 178개, 특성이 13개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame으로 나타내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(data.data, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(DF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Toy dataset으로 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "print(iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2 'setosa']\n",
      " [4.9 3.0 1.4 0.2 'setosa']\n",
      " [4.7 3.2 1.3 0.2 'setosa']\n",
      " [4.6 3.1 1.5 0.2 'setosa']\n",
      " [5.0 3.6 1.4 0.2 'setosa']\n",
      " [5.4 3.9 1.7 0.4 'setosa']\n",
      " [4.6 3.4 1.4 0.3 'setosa']\n",
      " [5.0 3.4 1.5 0.2 'setosa']\n",
      " [4.4 2.9 1.4 0.2 'setosa']\n",
      " [4.9 3.1 1.5 0.1 'setosa']\n",
      " [5.4 3.7 1.5 0.2 'setosa']\n",
      " [4.8 3.4 1.6 0.2 'setosa']\n",
      " [4.8 3.0 1.4 0.1 'setosa']\n",
      " [4.3 3.0 1.1 0.1 'setosa']\n",
      " [5.8 4.0 1.2 0.2 'setosa']\n",
      " [5.7 4.4 1.5 0.4 'setosa']\n",
      " [5.4 3.9 1.3 0.4 'setosa']\n",
      " [5.1 3.5 1.4 0.3 'setosa']\n",
      " [5.7 3.8 1.7 0.3 'setosa']\n",
      " [5.1 3.8 1.5 0.3 'setosa']\n",
      " [5.4 3.4 1.7 0.2 'setosa']\n",
      " [5.1 3.7 1.5 0.4 'setosa']\n",
      " [4.6 3.6 1.0 0.2 'setosa']\n",
      " [5.1 3.3 1.7 0.5 'setosa']\n",
      " [4.8 3.4 1.9 0.2 'setosa']\n",
      " [5.0 3.0 1.6 0.2 'setosa']\n",
      " [5.0 3.4 1.6 0.4 'setosa']\n",
      " [5.2 3.5 1.5 0.2 'setosa']\n",
      " [5.2 3.4 1.4 0.2 'setosa']\n",
      " [4.7 3.2 1.6 0.2 'setosa']\n",
      " [4.8 3.1 1.6 0.2 'setosa']\n",
      " [5.4 3.4 1.5 0.4 'setosa']\n",
      " [5.2 4.1 1.5 0.1 'setosa']\n",
      " [5.5 4.2 1.4 0.2 'setosa']\n",
      " [4.9 3.1 1.5 0.2 'setosa']\n",
      " [5.0 3.2 1.2 0.2 'setosa']\n",
      " [5.5 3.5 1.3 0.2 'setosa']\n",
      " [4.9 3.6 1.4 0.1 'setosa']\n",
      " [4.4 3.0 1.3 0.2 'setosa']\n",
      " [5.1 3.4 1.5 0.2 'setosa']\n",
      " [5.0 3.5 1.3 0.3 'setosa']\n",
      " [4.5 2.3 1.3 0.3 'setosa']\n",
      " [4.4 3.2 1.3 0.2 'setosa']\n",
      " [5.0 3.5 1.6 0.6 'setosa']\n",
      " [5.1 3.8 1.9 0.4 'setosa']\n",
      " [4.8 3.0 1.4 0.3 'setosa']\n",
      " [5.1 3.8 1.6 0.2 'setosa']\n",
      " [4.6 3.2 1.4 0.2 'setosa']\n",
      " [5.3 3.7 1.5 0.2 'setosa']\n",
      " [5.0 3.3 1.4 0.2 'setosa']\n",
      " [7.0 3.2 4.7 1.4 'versicolor']\n",
      " [6.4 3.2 4.5 1.5 'versicolor']\n",
      " [6.9 3.1 4.9 1.5 'versicolor']\n",
      " [5.5 2.3 4.0 1.3 'versicolor']\n",
      " [6.5 2.8 4.6 1.5 'versicolor']\n",
      " [5.7 2.8 4.5 1.3 'versicolor']\n",
      " [6.3 3.3 4.7 1.6 'versicolor']\n",
      " [4.9 2.4 3.3 1.0 'versicolor']\n",
      " [6.6 2.9 4.6 1.3 'versicolor']\n",
      " [5.2 2.7 3.9 1.4 'versicolor']\n",
      " [5.0 2.0 3.5 1.0 'versicolor']\n",
      " [5.9 3.0 4.2 1.5 'versicolor']\n",
      " [6.0 2.2 4.0 1.0 'versicolor']\n",
      " [6.1 2.9 4.7 1.4 'versicolor']\n",
      " [5.6 2.9 3.6 1.3 'versicolor']\n",
      " [6.7 3.1 4.4 1.4 'versicolor']\n",
      " [5.6 3.0 4.5 1.5 'versicolor']\n",
      " [5.8 2.7 4.1 1.0 'versicolor']\n",
      " [6.2 2.2 4.5 1.5 'versicolor']\n",
      " [5.6 2.5 3.9 1.1 'versicolor']\n",
      " [5.9 3.2 4.8 1.8 'versicolor']\n",
      " [6.1 2.8 4.0 1.3 'versicolor']\n",
      " [6.3 2.5 4.9 1.5 'versicolor']\n",
      " [6.1 2.8 4.7 1.2 'versicolor']\n",
      " [6.4 2.9 4.3 1.3 'versicolor']\n",
      " [6.6 3.0 4.4 1.4 'versicolor']\n",
      " [6.8 2.8 4.8 1.4 'versicolor']\n",
      " [6.7 3.0 5.0 1.7 'versicolor']\n",
      " [6.0 2.9 4.5 1.5 'versicolor']\n",
      " [5.7 2.6 3.5 1.0 'versicolor']\n",
      " [5.5 2.4 3.8 1.1 'versicolor']\n",
      " [5.5 2.4 3.7 1.0 'versicolor']\n",
      " [5.8 2.7 3.9 1.2 'versicolor']\n",
      " [6.0 2.7 5.1 1.6 'versicolor']\n",
      " [5.4 3.0 4.5 1.5 'versicolor']\n",
      " [6.0 3.4 4.5 1.6 'versicolor']\n",
      " [6.7 3.1 4.7 1.5 'versicolor']\n",
      " [6.3 2.3 4.4 1.3 'versicolor']\n",
      " [5.6 3.0 4.1 1.3 'versicolor']\n",
      " [5.5 2.5 4.0 1.3 'versicolor']\n",
      " [5.5 2.6 4.4 1.2 'versicolor']\n",
      " [6.1 3.0 4.6 1.4 'versicolor']\n",
      " [5.8 2.6 4.0 1.2 'versicolor']\n",
      " [5.0 2.3 3.3 1.0 'versicolor']\n",
      " [5.6 2.7 4.2 1.3 'versicolor']\n",
      " [5.7 3.0 4.2 1.2 'versicolor']\n",
      " [5.7 2.9 4.2 1.3 'versicolor']\n",
      " [6.2 2.9 4.3 1.3 'versicolor']\n",
      " [5.1 2.5 3.0 1.1 'versicolor']\n",
      " [5.7 2.8 4.1 1.3 'versicolor']\n",
      " [6.3 3.3 6.0 2.5 'virginica']\n",
      " [5.8 2.7 5.1 1.9 'virginica']\n",
      " [7.1 3.0 5.9 2.1 'virginica']\n",
      " [6.3 2.9 5.6 1.8 'virginica']\n",
      " [6.5 3.0 5.8 2.2 'virginica']\n",
      " [7.6 3.0 6.6 2.1 'virginica']\n",
      " [4.9 2.5 4.5 1.7 'virginica']\n",
      " [7.3 2.9 6.3 1.8 'virginica']\n",
      " [6.7 2.5 5.8 1.8 'virginica']\n",
      " [7.2 3.6 6.1 2.5 'virginica']\n",
      " [6.5 3.2 5.1 2.0 'virginica']\n",
      " [6.4 2.7 5.3 1.9 'virginica']\n",
      " [6.8 3.0 5.5 2.1 'virginica']\n",
      " [5.7 2.5 5.0 2.0 'virginica']\n",
      " [5.8 2.8 5.1 2.4 'virginica']\n",
      " [6.4 3.2 5.3 2.3 'virginica']\n",
      " [6.5 3.0 5.5 1.8 'virginica']\n",
      " [7.7 3.8 6.7 2.2 'virginica']\n",
      " [7.7 2.6 6.9 2.3 'virginica']\n",
      " [6.0 2.2 5.0 1.5 'virginica']\n",
      " [6.9 3.2 5.7 2.3 'virginica']\n",
      " [5.6 2.8 4.9 2.0 'virginica']\n",
      " [7.7 2.8 6.7 2.0 'virginica']\n",
      " [6.3 2.7 4.9 1.8 'virginica']\n",
      " [6.7 3.3 5.7 2.1 'virginica']\n",
      " [7.2 3.2 6.0 1.8 'virginica']\n",
      " [6.2 2.8 4.8 1.8 'virginica']\n",
      " [6.1 3.0 4.9 1.8 'virginica']\n",
      " [6.4 2.8 5.6 2.1 'virginica']\n",
      " [7.2 3.0 5.8 1.6 'virginica']\n",
      " [7.4 2.8 6.1 1.9 'virginica']\n",
      " [7.9 3.8 6.4 2.0 'virginica']\n",
      " [6.4 2.8 5.6 2.2 'virginica']\n",
      " [6.3 2.8 5.1 1.5 'virginica']\n",
      " [6.1 2.6 5.6 1.4 'virginica']\n",
      " [7.7 3.0 6.1 2.3 'virginica']\n",
      " [6.3 3.4 5.6 2.4 'virginica']\n",
      " [6.4 3.1 5.5 1.8 'virginica']\n",
      " [6.0 3.0 4.8 1.8 'virginica']\n",
      " [6.9 3.1 5.4 2.1 'virginica']\n",
      " [6.7 3.1 5.6 2.4 'virginica']\n",
      " [6.9 3.1 5.1 2.3 'virginica']\n",
      " [5.8 2.7 5.1 1.9 'virginica']\n",
      " [6.8 3.2 5.9 2.3 'virginica']\n",
      " [6.7 3.3 5.7 2.5 'virginica']\n",
      " [6.7 3.0 5.2 2.3 'virginica']\n",
      " [6.3 2.5 5.0 1.9 'virginica']\n",
      " [6.5 3.0 5.2 2.0 'virginica']\n",
      " [6.2 3.4 5.4 2.3 'virginica']\n",
      " [5.9 3.0 5.1 1.8 'virginica']]\n"
     ]
    }
   ],
   "source": [
    "print(iris.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(iris.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width\n",
      "0           5.1          3.5           1.4          0.2\n",
      "1           4.9          3.0           1.4          0.2\n",
      "2           4.7          3.2           1.3          0.2\n",
      "3           4.6          3.1           1.5          0.2\n",
      "4           5.0          3.6           1.4          0.2\n",
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "X = iris.drop('species', axis=1)\n",
    "print(X.head())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    setosa\n",
      "1    setosa\n",
      "2    setosa\n",
      "3    setosa\n",
      "4    setosa\n",
      "Name: species, dtype: object\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "y = iris[\"species\"]\n",
    "print(y.head())\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "classle = LabelEncoder()\n",
    "y = classle.fit_transform(iris[\"species\"].values)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (120,)\n",
      "(30, 4) (30,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 추정\n",
    "* E-2 아이리스 분류에서 다양한 모델을 다뤄보았습니다. 모델을 바꿔가면서 테스트를 해보세용 어떤 모델이 가장 성능이 좋을까요?\n",
    "* svm\n",
    "* `sklearn.tree`\n",
    "    * DecisionTreeClassifier\n",
    "* `sklearn.ensemble`\n",
    "    * RandomForestClassifier\n",
    "* `sklearn.linear_model`\n",
    "    * SGDClassifier\n",
    "    * LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "print(decision_tree._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 2, 2, 2, 1, 0, 0, 0, 1, 1, 2, 0, 2,\n",
       "       1, 1, 2, 2, 1, 0, 2, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = decision_tree.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 2, 2, 2, 1, 0, 0, 0, 1, 1, 2, 0, 2,\n",
       "       1, 2, 2, 1, 1, 0, 2, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  1  9]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = classification_report(y_test, y_pred)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여러가지 모델 훈련 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'svm': svm.SVC(),\n",
    "         'decision_tree': DecisionTreeClassifier(),\n",
    "         'rf': RandomForestClassifier(),\n",
    "         'sgd': SGDClassifier(),\n",
    "         'logistic': LogisticRegression()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_func():\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_test)\n",
    "        print(f\"model: {model_name}, accuracy: {accuracy_score(y_test, pred)}\")\n",
    "        print(\"--------\"*2+\"세부정보 보기\"+\"---------\"*2)\n",
    "        print(confusion_matrix(y_test, pred))\n",
    "        print(classification_report(y_test, pred))\n",
    "        print(\"---------\"*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: svm, accuracy: 0.9666666666666667\n",
      "----------------세부정보 보기------------------\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "---------------------------------------------\n",
      "model: decision_tree, accuracy: 0.9333333333333333\n",
      "----------------세부정보 보기------------------\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  1  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "---------------------------------------------\n",
      "model: rf, accuracy: 0.9333333333333333\n",
      "----------------세부정보 보기------------------\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  1  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "---------------------------------------------\n",
      "model: sgd, accuracy: 1.0\n",
      "----------------세부정보 보기------------------\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "---------------------------------------------\n",
      "model: logistic, accuracy: 0.9666666666666667\n",
      "----------------세부정보 보기------------------\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
